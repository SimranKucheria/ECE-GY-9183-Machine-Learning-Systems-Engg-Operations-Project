name: project3-etl

volumes:
  Project3Data:

services:
  extract-data:
    container_name: etl_extract_data
    image: python:3.11
    user: root
    volumes:
      - Project3Data:/data
    working_dir: /data

    command:
      - bash
      - -c
      - |
        set -e
        pip install pandas
        pip install numpy 
        python3 -c '
        import os
        import json
        import pandas as pd
        import numpy as np

        data_output_dir = "Dataset_Classifier"
        image_data_output_dir = os.path.join(data_output_dir, "images")
        train_csv_path = os.path.join(data_output_dir, "train.csv")
        val_csv_path = os.path.join(data_output_dir, "val.csv")

        if not os.path.exists(data_output_dir):
            os.makedirs(data_output_dir)

        aivshuman_image_dir = "/data/AiVsHuman/Images"
        aivshuman_csv_file = "/data/AiVsHuman/training.csv"

        flickr_image_dir = "/data/Flickr30k/Images"
        flickr_csv_file = "/data/Flickr30k/training.csv"


        aivshuman_data = pd.read_csv(aivshuman_csv_file)
        flickr_data = pd.read_csv(flickr_csv_file)

        print("AIVSHUMAN data shape:", aivshuman_data.shape)
        print("FLICKR data shape:", flickr_data.shape)

        print(aivshuman_data.head())
        print(flickr_data.head())
        print(aivshuman_data.shape)
        print(flickr_data.shape)

        human_data = aivshuman_data[aivshuman_data["label"] == 0]
        ai_data = aivshuman_data[aivshuman_data["label"] == 1]
        human_images = human_data["file_name"].tolist()
        ai_images = ai_data["file_name"].tolist()

        human_images = list(set(human_images))
        ai_images = list(set(ai_images))
 
        # Select random 10000 images with seed
        np.random.seed(42)
        human_images_final = np.random.choice(human_images, 12500, replace = False)
        ai_images_final = np.random.choice(ai_images, 12500, replace = False)

        #Combine the two lists
        final_shutterstock_images  = list(human_images_final) + list(ai_images_final)
        final_shutterstock_labels = [0] * len(final_shutterstock_images)

        flickr_images = flickr_data["image"].tolist()
        flickr_images = list(set(flickr_images))
        flickr_images_final = np.random.choice(flickr_images, 25000, replace = False)
        flickr_labels_final = [1] * len(flickr_images_final)
        
        #Join paths with the image names
        final_shutterstock_images = [os.path.join(aivshuman_image_dir, image) for image in final_shutterstock_images]
        flickr_images_final = [os.path.join(flickr_image_dir, image) for image in flickr_images_final]
        # Combine the two lists
        final_images = list(final_shutterstock_images) + list(flickr_images_final)
        final_labels = final_shutterstock_labels + flickr_labels_final

        # Create a dataframe
        df = pd.DataFrame({
            "image_name": final_images,
            "label": final_labels
        })
        # Shuffle the dataframe
        df = df.sample(frac=1, random_state=42).reset_index(drop=True)
        # Split the dataframe into train and val dataframes
        train_df = df.sample(frac=0.8, random_state=42)
        val_df = df.drop(train_df.index)
        # Save the dataframes to csv files
        train_df.to_csv(train_csv_path, index=False)
        val_df.to_csv(val_csv_path, index=False)
        '
        echo "Listing contents of /data/dataset_classifier after transform stage:"
        ls -l /data/Dataset_Classifier 

  load-data:
    container_name: etl_extract_data
    image: rclone/rclone:latest
    volumes:
      - Project3Data:/data
      - ~/.config/rclone/rclone.conf:/root/.config/rclone/rclone.conf:ro

    entrypoint: /bin/sh
    command:
      - -c
      - |
        if [ -z "$RCLONE_CONTAINER" ]; then
          echo "ERROR: RCLONE_CONTAINER is not set"
          exit 1
        fi
        echo "Cleaning up existing contents of container..."
        rclone delete chi_tacc:$RCLONE_CONTAINER --rmdirs || true

        echo "Copying data to container..."
        rclone copy /data/Dataset_Classifier chi_tacc:$RCLONE_CONTAINER \
        --progress \
        --transfers=32 \
        --checkers=16 \
        --multi-thread-streams=4 \
        --fast-list

        echo "Listing directories in container after load stage:"
        rclone lsd chi_tacc:$RCLONE_CONTAINER



