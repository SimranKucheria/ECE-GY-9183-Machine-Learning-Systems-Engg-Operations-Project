name: project3-etl

volumes:
  Project3Data:

services:
  extract-data:
    container_name: etl_extract_data
    image: python:3.11
    user: root
    volumes:
      - Project3Data:/data
    working_dir: /data

    command:
      - bash
      - -c
      - |
        set -e

        echo "Resetting dataset directory..."
        rm -rf Flickr30k
        mkdir -p Flickr30k
        cd Flickr30k

        echo "Downloading Flickr30k dataset zip..."
        curl -L https://www.kaggle.com/api/v1/datasets/download/adityajn105/flickr30k -o flickr30k-images.zip
        
        echo "Unzipping dataset..."
        unzip -q flickr30k-images.zip
        rm -f flickr30k-images.zip
        rm captions.txt
        curl -L https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_train.json -o flickr30k_train.json
        curl -L https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_val.json  -o flickr30k_val.json
        curl -L https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_test.json -o flickr30k_test.json
        mv /data/Flickr30k/Images /data/Flickr30k/flickr30k-images
        echo "Listing contents of /data after extract stage:"
        ls -l /data/Flickr30k

  transform-data:
    container_name: etl_transform_data
    image: python:3.11
    volumes:
      - Project3Data:/data
    working_dir: /data/Flickr30k
    environment:
      - test_split=0.5
    command:
      - bash
      - -c
      - |
        set -e
        python3 -c '
        import os
        import json
        import random

        random.seed(42)
        dataset_base_dir = "/data/Flickr30k"

        with open("flickr30k_test.json", "r") as f:
          data = json.load(f)
        
        
        idx = int(float(os.environ["test_split"])*len(data))
        
        with open("flickr30k_test_1.json", "w") as f:
                json.dump(data[0:idx],f)
        with open("flickr30k_test_online.json", "w") as f:
                json.dump(data[idx:],f)        
        

        val_file = "flickr30k_val.json" 
        test_file = "flickr30k_test_1.json"
        test_online_file = "flickr30k_test_online.json"

        def generate_new_format(file_name):
            with open(file_name, "r") as f:
                data = json.load(f)

            
            final_data = dict()
            final_data["annotations"] = list()
            final_data["images"] = list()
 
            for item in data:
                path = item["image"]
                captions = item["caption"]
                image_id = path.split("/")[-1].strip(".jpg").split("_")[-1]
                image_id = int(image_id)

                for caption in captions:
                    final_data["annotations"].append(
                        {
                            "image_id": image_id,
                            "caption": caption,
                            "id": len(final_data["annotations"]) + 1
                        }
                    ) 
                
                final_data["images"].append(
                    {
                        "id": image_id,
                    }
                )
            # Save the final data to a new JSON file
            with open(file_name.replace(".json", "_gt.json"), "w") as f:
                json.dump(final_data, f, indent=4)

        generate_new_format(val_file)
        generate_new_format(test_file)
        generate_new_format(test_online_file)
        '
        rm flickr30k_test.json
        mv flickr30k_test_1.json flickr30k_test.json
        mv flickr30k_test_1_gt.json flickr30k_test_gt.json
        echo "Listing contents of /data/Flickr30k after transform stage:"
        ls -l /data/Flickr30k
  
  simulate-online-data:
    container_name: etl_simulate_online_data
    image: python:3.11
    depends_on:
      - fastapi_server
    volumes:
      - Project3Data:/data
    working_dir: /data
    environment:
      - FASTAPI_URL=http://fastapi_server:8000/predict
      - LOAD_PATTERN=1,2,3,5,3,2,1
      - DELAY_BETWEEN_STEPS=60
      - REQUEST_TIMEOUT=5
    command:
      - bash
      - -c
      - |
        set -e
        pip install requests pillow
        echo "Running online data simulator..."
        python3 /data/online_data_simulator_blip.py